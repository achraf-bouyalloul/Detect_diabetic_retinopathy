# -*- coding: utf-8 -*-
"""dasnetV1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14sU9f-Dzl6AChwhgdmH3eoDuKiHQ6SDt
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import matplotlib.pyplot as plt
import numpy as np
from keras.applications import DenseNet121
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import Callback
from sklearn.model_selection import train_test_split

# Callback personnalisé pour visualiser l'entraînement en temps réel
class TrainingVisualizer(Callback):
    def __init__(self):
        self.train_loss_history = []
        self.train_accuracy_history = []

    def on_epoch_end(self, epoch, logs=None):
        self.train_loss_history.append(logs['loss'])
        self.train_accuracy_history.append(logs['accuracy'])

        # Tracer les courbes de perte et d'exactitude
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 2, 1)
        plt.plot(self.train_loss_history)
        plt.xlabel('Époque')
        plt.ylabel('Perte')
        plt.title('Courbe de perte d\'entraînement')

        plt.subplot(1, 2, 2)
        plt.plot(self.train_accuracy_history)
        plt.xlabel('Époque')
        plt.ylabel('Exactitude')
        plt.title('Courbe d\'exactitude d\'entraînement')

        plt.show()

# Dimensions des images en entrée du modèle DenseNet
input_shape = (224, 224, 3)

# Charger le modèle DenseNet pré-entraîné (sans les couches de classification)
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)

# Ajouter des couches de classification personnalisées
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)  # Ajoutez des couches Dense supplémentaires si nécessaire
predictions = Dense(5, activation='softmax')(x)  # 5 classes pour votre cas
# Créer le modèle final à entraîner
model = Model(inputs=base_model.input, outputs=predictions)
# Compiler le modèle
model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])


chemin_data="chemin-dossier-des-images" # choisier le dossier cintienr les cinq sossier de classe 0 1 2 3 4 (tu peut chosi filtre ou sans filtre)


# Définir le chemin vers le dossier contenant les images d'entraînement classées par classe
train_data_dir = chemin_data
# Utiliser le générateur d'images pour l'entraînement avec gestion des erreurs
batch_size = 32
train_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(input_shape[0], input_shape[1]),
    batch_size=batch_size,
    class_mode='categorical'
)

# Entraîner le modèle avec le callback de visualisation
num_epochs = 15
steps_per_epoch = train_generator.n // train_generator.batch_size

training_visualizer = TrainingVisualizer()

# Training loop
for epoch in range(num_epochs):
    print(f"Epoch {epoch+1}/{num_epochs}")
    for step in range(steps_per_epoch):
        x_batch, y_batch = next(train_generator)
        loss, accuracy = model.train_on_batch(x_batch, y_batch)
        print(f"Step {step+1}/{steps_per_epoch} - Loss: {loss:.4f} - Accuracy: {accuracy:.4f}")

    # Call the training visualizer callback to plot training progress after each epoch
    training_visualizer.on_epoch_end(epoch, {'loss': loss, 'accuracy': accuracy})


chemin_vers_model_weights="chemin-enregistrer-model-version_weights" # chemin ou tu peut enrgestrer votre model
chemin_vers_model="chemin-enregistrer-model-version_weights" # chemin ou tu peut enrgestrer votre model
# Après l'entraînement
model.save_weights(chemin_vers_model_weights)
# Sauvegarder le modèle entraîné
model.save(chemin_vers_model)