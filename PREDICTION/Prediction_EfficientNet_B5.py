# -*- coding: utf-8 -*-
"""transformation_data_2015_2019.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J4n2az5s0ULlPeiO_GD0fLrtH9ZWC6BS
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import matplotlib.pyplot as plt
import numpy as np
from keras.applications import DenseNet121
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras.optimizers import Adam
from PIL import Image
import shutil


# Répertoire contenant vos données d'entraînement
train_data_dir = '/content/drive/MyDrive/class_processed'

# Nombre de classes dans votre ensemble de données
num_classes = 5

# Dimensions des images en entrée
input_shape = (224, 224)

# Créer le modèle EfficientNetB5 pré-entraîné sans la couche de classification finale
base_model = EfficientNetB5(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Ajouter une nouvelle couche de classification adaptée à votre tâche
x = GlobalAveragePooling2D()(base_model.output)
output = Dense(num_classes, activation='softmax')(x)

# Créer le modèle final
model = Model(inputs=base_model.input, outputs=output)

# Compiler le modèle
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


# Compiler le modèle
model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Charger les poids du modèle sauvegardés
model.load_weights('/content/drive/MyDrive/model_weightsV2.h5')

# Chemin vers le dossier contenant les images à prédire
folder_path = '/content/drive/MyDrive/class 2015/0'

# Liste des fichiers d'images dans le dossier
image_files = os.listdir(folder_path)

# Effectuer les prédictions pour chaque image dans le dossier
for image_file in image_files:
    image_path = os.path.join(folder_path, image_file)
    image = Image.open(image_path)
    image = image.resize((input_shape[0], input_shape[1]))
    image_array = np.array(image)
    image_array = np.expand_dims(image_array, axis=0)
    image_array = image_array.astype('float32')
    image_array /= 255.0

    # Effectuer la prédiction
    predictions = model.predict(image_array)

    # Les prédictions seront un tableau numpy contenant les probabilités d'appartenance à chaque classe
    # Vous pouvez utiliser la fonction argmax pour obtenir l'indice de la classe prédite avec la plus haute probabilité
    predicted_class_index = np.argmax(predictions)

    print("Prédictions enregistrées dans", predictions)

